{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cguav7TTWJO1"
      },
      "source": [
        "# Lab 4. Tensorflow models 2 (CNN and RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRvXsZafK-Mv"
      },
      "source": [
        "In this lab, we will continue to investigate CNN and also try making a new RNN model on sequential datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MC0zULyhTG5o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDK0b5o3TG5q"
      },
      "source": [
        "### Section 1: Larger and more complex image dataset / Tensorflow datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2v3SqTpWsS6"
      },
      "source": [
        "In Fashion MNIST classification, the subject is always in the ``center`` of a 28x28 image. This means the network only needs to get important features from a fixed area.\n",
        "\n",
        "However, in this section, we will take it to the next level, training to recognize features in an image where the subject can be ``anywhere`` in the image - Building a ``horses-or-humans`` classifier that will tell you if a given image contains a horse or a human, where the network is trained to recognize features that determine which is which.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yT_wLckK-Mx"
      },
      "source": [
        "We first need to download the dataset. This time, we will use `tensorflow_datasets` module to download one of the famous datasets in this area. You can import it as below if you already have it. Note that this is not part of the `tensorflow` build so you may need to install it using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "NmdMerwv7VmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check the catalog with `list_builders()` or on the [website](https://www.tensorflow.org/datasets/)."
      ],
      "metadata": {
        "id": "IERmnnvg8Q8y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u_cF9qby7Mb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Today we will use the **Horses or Humans** dataset... You can use `tfds.load` function to load a specific data in the catalog."
      ],
      "metadata": {
        "id": "PHKJIHlR8cS5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ay_A8osKWyif"
      },
      "outputs": [],
      "source": [
        "# tfds.load\n",
        "# - split [train, valid, test]\n",
        "# - shuffle_files\n",
        "# - as_supervised\n",
        "# with_info\n",
        "((train_ds, valid_ds, test_ds), info) = None"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the type of those three datasets\n",
        "train_ds, valid_ds, test_ds"
      ],
      "metadata": {
        "id": "nnVY_yqh8sJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check the size by using `.cardinality()` since those are in the `tf.Data` format."
      ],
      "metadata": {
        "id": "WoCx2JFMIb6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.cardinality(), valid_ds.cardinality(), test_ds.cardinality()"
      ],
      "metadata": {
        "id": "AgV1znPvIeNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you set `with_info=True`, you can check some information of the dataset."
      ],
      "metadata": {
        "id": "TALNCmwBZ1N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "id": "ete7sGm28v3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUUg25F_K-M2"
      },
      "source": [
        "Some examples ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TpnO9Zl3HOl"
      },
      "outputs": [],
      "source": [
        "sample = train_ds.take(1)\n",
        "for example in sample:\n",
        "  imgplot = plt.imshow(example[0])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPu2vgDR3VpY"
      },
      "outputs": [],
      "source": [
        "sample = train_ds.take(1)\n",
        "for example in sample:\n",
        "  imgplot = plt.imshow(example[0])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use `tf.Data` functions sich as `batch` and `prefetch` directly since those datasets are in tf.Data format.\n",
        " - [Prefetch and cache](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwim-q_1l4T9AhU0RvEDHUj1Cx4QtwJ6BAhEEAI&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DMLEKEplgCas&usg=AOvVaw2anFNZFGU675DMnyVTqDZ1)\n",
        " - [tf.data.AUTOTUNE](https://www.tensorflow.org/guide/data_performance)"
      ],
      "metadata": {
        "id": "6uhNz1tYH3MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = None\n",
        "valid_ds = None\n",
        "test_ds = None"
      ],
      "metadata": {
        "id": "pSqdbBzH7H6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkNpqVyQK-M4"
      },
      "source": [
        "Now we can try making a CNN model. Let's make a bit deeper model than the one we created in the last lab. We should also not forget about **rescaling**, but this time we do this by creating a new layer called `Rescaling`.\n",
        " - [What is fully convolutional network?](https://ai.stackexchange.com/questions/21810/what-is-a-fully-convolution-network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTJmXzOM6ir3"
      },
      "outputs": [],
      "source": [
        "#### CNN MODELS (Sequential) ####\n",
        "# activation\n",
        "# padding - same, valid\n",
        "# pooling\n",
        "# dropout\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Another way of scaling the data (Rescaling(1./255, input_shape=(300, 300, 3)))\n",
        "\n",
        "    # The first convolution (Conv2D, 16, (3,3), relu) + MaxPooling2D\n",
        "\n",
        "    # The second convolution (32, (3,3))\n",
        "\n",
        "    # The third convolution (64)\n",
        "\n",
        "    # The fourth convolution (64)\n",
        "\n",
        "    # The fifth convolution (64)\n",
        "\n",
        "    # Flatten the results to feed into a DNN\n",
        "\n",
        "    # hidden layer with 512 neurons\n",
        "\n",
        "    # Only 1 output neuron with the sigmoid function. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S39OkU7BK-M4"
      },
      "source": [
        "You can always check the parameter size of your model with `model.summary()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Xdd-mVeK-M4",
        "outputId": "2bf62124-ff0b-4667-dba1-6e535b77f3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_3 (Rescaling)     (None, 300, 300, 3)       0         \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 298, 298, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 149, 149, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 147, 147, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 73, 73, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 71, 71, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 35, 35, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 33, 33, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 7, 7, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               1606144   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,704,097\n",
            "Trainable params: 1,704,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXnkZDJSK-M5"
      },
      "source": [
        "Here we have a binary classification problem so we can set the binary cross-entropy loss function, and we can also specify any optimizer that we prefer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44wV10F76qzH"
      },
      "outputs": [],
      "source": [
        "# Complie the model\n",
        "# - loss = binary crossentropy\n",
        "# - optimizer = RMSprop with learning rate 0.001\n",
        "# - metrics = accuracy\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU6uLzYMK-M5"
      },
      "source": [
        "We can finally fit our model on the dataset. There can be different strategy for different method to create the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7za_O-Z6ukc"
      },
      "outputs": [],
      "source": [
        "# Fit the model (train_ds, valid_ds, 10 epochs)\n",
        "history = model.fit(\n",
        "      train_ds,\n",
        "      validation_data = valid_ds,  \n",
        "      epochs=10,\n",
        "      verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test_ds\n",
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "bdasSPgwLXDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_VJaf9uWwFA"
      },
      "source": [
        "### Section 2: Use a pretrained CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRtN4Rtc98iz"
      },
      "source": [
        "Sometimes, especially when you have a big amount of data, you may not be able to get a good enough performance, and this happens most of the times when you work on the actual project. In this case, you can always use pretrained models available from Keras. Those networks are already trained on massive amount of the data so you can generally get better results after you tweak the model a bit and train it on your own problem.\n",
        "- [List of pretrained models in keras.application](https://keras.io/api/applications/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG network can be found from keras.applications\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "metadata": {
        "id": "4IYQRiypK3Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can call the model by initializing the imported class (e.g., VGG16())."
      ],
      "metadata": {
        "id": "pHe-E-JUc9HM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGm0iDEpXZIx"
      },
      "outputs": [],
      "source": [
        "# Import the model by calling VGG16() and get the summary (model structure). Notice the input size.\n",
        "model_vgg = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqDpaemAK-M6"
      },
      "source": [
        "We can change some part of this pretrained model to make it adjust to our dataset. Normally we change two parts:\n",
        " - Input layer\n",
        " - Output layer\n",
        "\n",
        "The block below is calling the pretrained model but replacing the input layer. However, that is not always the case as we can also change our input to have the same shape by applying preprocessing method that the pretrained model has."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0txcnBIMcKd"
      },
      "outputs": [],
      "source": [
        "# 'include_top' and 'input_tensor' are two main functions we need to change!\n",
        "# For input_tensor, you specify keras' input layer (keras.layers.Input) with your iamge size\n",
        "# We can also change the 'pooling' method for \"output\"\n",
        "model_base = None\n",
        "model_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikc-7E5zK-M6"
      },
      "source": [
        "When we use a pretrained model, we normally make the model not trainable except for the first layer where we put our new images, and if the model does not have a fully connected layer, we can also put few more layers to return correct size output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVb3mvLQMNK4"
      },
      "outputs": [],
      "source": [
        "def vgg():\n",
        "  ############################\n",
        "  # You need to freeze the pre-trained weights first time\n",
        "\n",
        "  ############################\n",
        "\n",
        "  model = keras.Sequential([\n",
        "      model_base,\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(128, activation='relu', name='dense_1'),\n",
        "      keras.layers.Dropout(0.5, name='drop_1'),\n",
        "      keras.layers.Dense(64, activation='relu', name='dense_2'),\n",
        "      keras.layers.Dropout(0.5, name='drop_2'),\n",
        "      keras.layers.Dense(1, activation='sigmoid', name='output')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=0.01),\n",
        "              metrics=['acc'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUlHa_vmK-M6"
      },
      "source": [
        "We can define our compiled model and use the `EarlyStopping` callback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO0wBYofMbqd"
      },
      "outputs": [],
      "source": [
        "model_vgg = vgg()\n",
        "\n",
        "# We can also have an early stopping callback\n",
        "# - min_delta\n",
        "# - patience\n",
        "# - restore_best_weights\n",
        "\n",
        "early_stopping = None\n",
        "\n",
        "# When the model stop making any meaningful progress ...\n",
        "history = model_vgg.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can always check the test accuracy."
      ],
      "metadata": {
        "id": "3CcoZDxiukJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "QXlu1c1SMQ-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After few epochs, you can fine-tune the pre-trained "
      ],
      "metadata": {
        "id": "tvT8U4T2umGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FINE TUNING DOES NOT ALWAYS YIELD A BETTER RESULT\n",
        "for layer in model_vgg.layers: \n",
        "  layer.trainable = True \n",
        "  \n",
        "model_vgg.compile(loss='binary_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=0.0001), # Much lower learning rate!\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model_vgg.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    epochs=5,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "LHUP7LD_6E2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "V2CKuYDwNGtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDqMD7z0Xad4"
      },
      "source": [
        "### Section 3: Recurrent neural network - SimpleRNN, GNU, LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ8qp7WbK-M7"
      },
      "source": [
        "Now we move on to RNN! Creating a RNN network is much simpler than creating CNN networks which require many different convolutional filters and kernels. You can create a working RNN network only with few lines. Here we will first look into different models on a simple synthetic data. After that we will investigate more by creating a model for sentimental analysis. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTONVz5STG5r"
      },
      "outputs": [],
      "source": [
        "def generate_time_series(batch_size, n_steps):\n",
        "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
        "    time = np.linspace(0, 1, n_steps)\n",
        "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  #   wave 1\n",
        "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
        "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # + noise\n",
        "    return series[..., np.newaxis].astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXepdRAfK-M7"
      },
      "source": [
        "Here we generate 10,000 time series instances of length 51 and use 70% as a training set. We will put first 50 data points to the model to predict the last data point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05E2RwILTG5r"
      },
      "outputs": [],
      "source": [
        "np.random.seed(12345)\n",
        "n_steps = 50\n",
        "series = generate_time_series(10000, n_steps + 1)\n",
        "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
        "X_test, y_test = series[7000:, :n_steps], series[7000:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to check the special axis at the end to indicate the sequential data."
      ],
      "metadata": {
        "id": "2qHp0mKBvXGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "Le-rQAkIvOH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVZISjMyK-M7"
      },
      "source": [
        "Here you can check few examples of our synthetic time series. Our objective is to create a model to predict these blue Xs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNrUHYJ6TG5s"
      },
      "outputs": [],
      "source": [
        "def plot_series(series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\"):\n",
        "    plt.plot(series, \".-\")\n",
        "    if y is not None:\n",
        "        plt.plot(n_steps, y, \"bx\", markersize=10)\n",
        "    if y_pred is not None:\n",
        "        plt.plot(n_steps, y_pred, \"ro\")\n",
        "    plt.grid(True)\n",
        "    if x_label:\n",
        "        plt.xlabel(x_label, fontsize=16)\n",
        "    if y_label:\n",
        "        plt.ylabel(y_label, fontsize=16, rotation=0)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, sharey=True, figsize=(12, 4))\n",
        "for col in range(3):\n",
        "    plt.sca(axes[col])\n",
        "    plot_series(X_test[col, :, 0], y_test[col, 0], y_label=(\"$x(t)$\" if col==0 else None))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivNKcIN9K-M7"
      },
      "source": [
        "We will create the following models on the same dataset:\n",
        " - Fully connected network\n",
        " - Simple RNN\n",
        " - Deep RNN \n",
        " - LSTM\n",
        " - GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5UzbwWlTG5s"
      },
      "source": [
        "#### Fully connected network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fully connected network can also handle sequential data by regarding each time point input independently."
      ],
      "metadata": {
        "id": "l4AjivJLkAdQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgENVHjNTG5s"
      },
      "outputs": [],
      "source": [
        "# Why do we need this Flatten layer?\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[50, 1]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "history = model.fit(X_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqJr_Y_7TG5t"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUSyx4bgTG5t"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "plot_series(X_test[0, :, 0], y_test[0, 0], y_pred[0, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_TjpFAsTG5t"
      },
      "source": [
        "#### Vanilla RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can move on to the simplest RNN network having only one hidden state. This does not have any practical value.\n",
        "- Vanilla RNN is called `SimpleRNN` in keras.\n",
        "- You do not need to specify the input shape as it will be unrolled based on the time steps (second axis)."
      ],
      "metadata": {
        "id": "2kCcaPITj_EU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRx-t4MaY56m"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "  ####################################\n",
        "\n",
        "  ####################################\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Snk3oO9cY6v5",
        "outputId": "2d6fb12d-dd06-4756-a5c8-f3fc0f39660a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiuuzvSSTG5t"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(lr=0.005))\n",
        "history = model.fit(X_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Un40iPKxTG5t"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bZFeNZgTG5t"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "plot_series(X_test[0, :, 0], y_test[0, 0], y_pred[0, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t01LPy3NTG5u"
      },
      "source": [
        "#### Deep RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can have more than one RNN layers to let the network learn a bit more complex patterns. Here we have a new important option.\n",
        " - `return_sequences`"
      ],
      "metadata": {
        "id": "3ra1wSPZkUm1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8smVjIrhTG5u"
      },
      "outputs": [],
      "source": [
        "# Two SimpleRNN with 20 hidden neurons and return_sequences=True\n",
        "# Last layer with one simpleRNN with one neuron without return_sequences\n",
        "model = keras.models.Sequential([\n",
        "  ####################################\n",
        "\n",
        "  ####################################\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sClfQiQEK-M9",
        "outputId": "85ec32da-5b0c-446a-e1ab-449ed5f1607d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_6 (SimpleRNN)    (None, None, 20)          440       \n",
            "                                                                 \n",
            " simple_rnn_7 (SimpleRNN)    (None, None, 20)          820       \n",
            "                                                                 \n",
            " simple_rnn_8 (SimpleRNN)    (None, 1)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,282\n",
            "Trainable params: 1,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8oS6al7K-M9"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "history = model.fit(X_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXdfhBtkTG5u"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6h-wOWaTG5u"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "plot_series(X_test[0, :, 0], y_test[0, 0], y_pred[0, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze725gJ8TG5v"
      },
      "source": [
        "#### LSTM & GRU: In practice, these networks work as same as simpleRNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45eQBUO1TG5v"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
        "    keras.layers.LSTM(20),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "history = model.fit(X_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWA8OOTqTG5v"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-Y1_DaDTG5v"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "plot_series(X_test[0, :, 0], y_test[0, 0], y_pred[0, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMSPwBqPTG5w"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
        "    keras.layers.GRU(20),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "history = model.fit(X_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is0K4zlWTG5w"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxEx8B5DTG5w"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "plot_series(X_test[0, :, 0], y_test[0, 0], y_pred[0, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### More than one point?"
      ],
      "metadata": {
        "id": "rRxU2U3ik6Ey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can always let model predict more than one point. There can be many ways as follows:\n",
        "- Let model predict one step ahead and feed it again to the model to predict the next one.\n",
        "- **Let model predict ten steps all together at the last step.**\n",
        "- Let model predict ten steps all together at each time step.\n",
        "\n"
      ],
      "metadata": {
        "id": "VcBryXbamgCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_steps = 50\n",
        "series = generate_time_series(10000, n_steps + 10)\n",
        "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]\n",
        "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
        "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
      ],
      "metadata": {
        "id": "0zk2jLzWnQP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
        "    keras.layers.SimpleRNN(20),\n",
        "    keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "\n",
        "#\n",
        "# Remember the last model predicting one point!!\n",
        "#\n",
        "# model = keras.models.Sequential([\n",
        "#     keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
        "#     keras.layers.GRU(20),\n",
        "#     keras.layers.Dense(1)\n",
        "# ])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "history = model.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "metadata": {
        "id": "5yAGdunknYaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_multiple_forecasts(X, Y, Y_pred):\n",
        "    n_steps = X.shape[1]\n",
        "    ahead = Y.shape[1]\n",
        "    plot_series(X[0, :, 0])\n",
        "    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"bo-\", label=\"Actual\")\n",
        "    plt.plot(np.arange(n_steps, n_steps + ahead), Y_pred[0, :, 0], \"rx-\", label=\"Forecast\", markersize=10)\n",
        "    plt.axis([0, n_steps + ahead, -1, 1])\n",
        "    plt.legend(fontsize=14)\n",
        "\n",
        "np.random.seed(43)\n",
        "\n",
        "series = generate_time_series(1, 50 + 10)\n",
        "X_new, Y_new = series[:, :50, :], series[:, -10:, :]\n",
        "Y_pred = model.predict(X_new)[..., np.newaxis]\n",
        "plot_multiple_forecasts(X_new, Y_new, Y_pred)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KFUz1-kxnbbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgdVcCxsX4X1"
      },
      "source": [
        "### Task 1: Use another pretrained CNN model on the image dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdd47OTuK-NA"
      },
      "source": [
        "We have tried a pretrained VGG16 model in the lab. Now, you can try to use different pretrained CNN model and see if you can further improve the performance compared to your own CNN model. You can check many different pretrained models on [the Keras website](https://keras.io/api/applications/). Please also note that some of the networks may not work well without `preprocess_input()`. You do not need to fine-tune the pretrained weights but need to create your own input/output layers and train them at least for 10 epochs.\n",
        "\n",
        "- Here you need to choose any dataset from the tenorflow dataset catalog.\n",
        "- You should use at least **two** Tensorflow callbacks when you fit your model. These can be built-in ones or your personalized callback.\n",
        "- You should use Tensorflow's data API (`tf.data`) to manage your dataset and use `shuffle`, `batch`, and `prefetch` functions.\n",
        "- Compare the result in terms of the test accuracy from `VGG16` model and your new chosen model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE7jS2e7fzqm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7aLFeUSX2zp"
      },
      "source": [
        "### Task 2: Time series classification using CNN or RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPT3f5DSK-NA"
      },
      "source": [
        "We have used RNN networks for time series forecasting problem. Those models can also be easily used for time series classification with different output layers, activation functions, and error functions. Here we will use one famous dataset called **FordA**. \n",
        "\n",
        "One more interesting thing we can try is to use the CNN network instead of RNN to catch some patterns for the classification task. Since time series only have one dimension, we may need to use 1D-CNN. Of course we can always start from the traditional fully connected network as well. We can even merge CNN and RNN - the easiest way is to apply CNNs first and feed the output to any RNN network.\n",
        " - [keras.layers.Conv1D](https://keras.io/api/layers/convolution_layers/convolution1d/)\n",
        "\n",
        "Try four different models: 1) Fully connected network, 2) RNN only (any variant), 3) 1D-CNN only, and 4) 1D-CNN + RNN. You can freely construct any structure you want. Report the best model in terms of **accuracy** on the test set among four. There is no definitive answer and it is up to your own model. Here you need to keep the following rules:\n",
        "\n",
        "- You should use at least **two** Tensorflow callbacks when you fit your model. These can be built-in ones or your personalized callback.\n",
        "- You should use Tensorflow's data API (`tf.data`) to manage your dataset and use `shuffle`, `batch`, and `prefetch` functions. This means that you need to convert the data format using the `from_tensor_slices` function.\n",
        "- You need to validate your model for each epoch. You should create your validation set using `tf.Data` methods.\n",
        "- You need to clearly plot the test accuracy of the four models.\n",
        "- For the 1D-CNN+RNN network, you do not need to apply any pooling layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ko9Bjq9cX5Tc"
      },
      "outputs": [],
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "X_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "X_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}